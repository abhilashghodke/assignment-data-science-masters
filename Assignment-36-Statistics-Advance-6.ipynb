{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2ad083-2dda-4db6-ab67-f7f3e9c8c734",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1de7b-09fd-4dd3-8a69-591e14eb3022",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across two or more groups to determine whether there are any statistically significant differences among them. However, ANOVA comes with certain assumptions that need to be met for the results to be valid. These assumptions are crucial because violations can lead to inaccurate or misleading conclusions. The assumptions for ANOVA are as follows:\n",
    "\n",
    "**1. Independence:** The observations within each group and between groups should be independent of each other. This means that the data points in one group should not be influenced by or related to the data points in other groups.\n",
    "\n",
    "**2. Normality:** The residuals (the differences between observed values and predicted values) should follow a normal distribution within each group. Normality assumption ensures that the sampling distribution of the means is also normal, which is important for making valid inferences.\n",
    "\n",
    "**3. Homogeneity of Variance (Homoscedasticity):** The variance of the residuals should be roughly constant across all levels of the independent variable. In other words, the spread of data points around the mean should be approximately equal across different groups.\n",
    "\n",
    "**4. Equal Sample Sizes (for one-way ANOVA):** In a one-way ANOVA, if you have multiple groups, it's ideal to have roughly equal sample sizes in each group. This helps to maintain the validity of the F-test used in ANOVA.\n",
    "\n",
    "**5. Random Sampling:** The data should be collected using random sampling methods, so the results can be generalized to the larger population from which the samples were drawn.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "**1. Non-Independence:** If the data points within or between groups are not independent, it can lead to issues. For instance, if observations in one group are influenced by those in another group, the assumption of independence is violated.\n",
    "\n",
    "**2. Non-Normality:** If the residuals within each group do not follow a normal distribution, it can lead to incorrect p-values and confidence intervals. This can happen when the data is heavily skewed or has outliers.\n",
    "\n",
    "**3. Violation of Homoscedasticity:** When the variability of residuals differs significantly across groups, the assumption of homogeneity of variance is violated. This can impact the accuracy of the F-test and the validity of the ANOVA results.\n",
    "\n",
    "**4. Unequal Sample Sizes:** In one-way ANOVA, having unequal sample sizes can affect the power of the test and potentially lead to biased results. It's generally recommended to have approximately equal sample sizes in each group.\n",
    "\n",
    "**5. Non-Random Sampling:** If the data is not collected using proper random sampling techniques, the results might not be generalizable to the larger population.\n",
    "\n",
    "When these assumptions are violated, it's important to consider alternative statistical methods or transformations of the data that might be more appropriate for your analysis. Additionally, it's always good practice to visually inspect your data using diagnostic plots to assess the assumptions before relying on ANOVA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac5547-5174-44ed-b1dd-21c96f6445d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe496e1-0b00-4159-8f48-5d2d42e25f4a",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb4d95-8e86-4bb3-bc70-b28a80ea1911",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "There are three main types of Analysis of Variance (ANOVA) techniques, each designed for specific types of experimental designs and research questions:\n",
    "\n",
    "**1. One-Way ANOVA:**\n",
    "One-Way ANOVA is used when you have one independent variable (factor) with three or more levels (groups) and you want to determine if there are any significant differences in means among these groups. This is suitable when you're comparing means across multiple categories.\n",
    "\n",
    "Example: A pharmaceutical company wants to test the effectiveness of three different doses of a new drug by administering it to three different groups of patients.\n",
    "\n",
    "**2. Two-Way ANOVA:**\n",
    "Two-Way ANOVA is used when you have two independent variables (factors) and you want to assess the effects of each factor on the dependent variable, as well as any interaction between the factors. It's suitable for designs where you're interested in studying the combined effects of two factors.\n",
    "\n",
    "Example: A study examines the effects of both gender and diet on weight loss. The study has two independent variables: gender (male or female) and diet type (low-carb, high-protein, balanced). Two-Way ANOVA would help determine the individual and combined effects of gender and diet on weight loss.\n",
    "\n",
    "**3. Repeated Measures ANOVA:**\n",
    "Repeated Measures ANOVA (also known as Within-Subjects ANOVA) is used when the same subjects are measured under different conditions or at different time points. It's used to analyze within-subject variations over time or across conditions.\n",
    "\n",
    "Example: A study measures the performance of the same group of students on a test before training, after one week of training, and after two weeks of training. Repeated Measures ANOVA would be used to analyze whether there are any significant differences in test scores across the different time points.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- **One-Way ANOVA**: Used for comparing means across three or more independent groups.\n",
    "- **Two-Way ANOVA**: Used for studying the effects of two independent variables and their interactions on a dependent variable.\n",
    "- **Repeated Measures ANOVA**: Used for analyzing within-subject variations across different conditions or time points.\n",
    "\n",
    "It's important to choose the appropriate type of ANOVA based on your research design and objectives. Additionally, it's always a good practice to check for the assumptions of ANOVA before interpreting the results. If the assumptions are violated, alternative methods or transformations may be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012c57a-e391-419e-ad6d-1569e1ed4452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b537c962-ef68-423e-85bb-f2bda560e9f4",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312b027-5311-4825-89a2-85b80073c7c3",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "Partitioning of variance in ANOVA refers to the process of decomposing the total variability in the data into different sources of variability or \"components.\" This decomposition helps us understand the contributions of different factors or sources to the overall variability observed in the dependent variable. The partitioning of variance is a fundamental concept in ANOVA, and it provides valuable insights into the sources of variation and the significance of those sources.\n",
    "\n",
    "In ANOVA, the total variance of the dependent variable is divided into three main components:\n",
    "\n",
    "1. **Between-Groups Variance (Variability between groups):** This component of variance represents the variability in the dependent variable that can be attributed to differences between the group means. It indicates whether the means of different groups are significantly different from each other.\n",
    "\n",
    "2. **Within-Groups Variance (Variability within groups):** This component of variance represents the variability in the dependent variable within each group. It reflects the natural variability and measurement error present within individual groups.\n",
    "\n",
    "3. **Error Variance (Unexplained variability):** Error variance, also known as residual variance, represents the unexplained variability in the dependent variable that cannot be attributed to the factors being studied. It includes any sources of variability that are not accounted for by the model.\n",
    "\n",
    "Mathematically, the total variance (Total SS) can be partitioned as follows:\n",
    "Total SS = Between-Groups SS + Within-Groups SS\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. **Interpretation of Results:** By decomposing the total variance into these components, ANOVA allows you to assess the contributions of different factors to the overall variability. This helps you understand which factors are significant in explaining the differences among groups.\n",
    "\n",
    "2. **Hypothesis Testing:** ANOVA uses the partitioning of variance to perform hypothesis tests. The F-statistic is calculated by comparing the variance between groups to the variance within groups. This F-test helps determine whether the group means are significantly different.\n",
    "\n",
    "3. **Model Validation:** By examining the portion of variability that is unexplained (error variance), you can assess how well the model fits the data. If the error variance is small compared to the total variance, it suggests that the model is explaining a substantial portion of the variability.\n",
    "\n",
    "4. **Identifying Sources of Variation:** Partitioning of variance helps researchers identify which factors are contributing the most to the observed variation. This can guide further investigation and help make informed decisions.\n",
    "\n",
    "5. **Design and Planning:** When designing experiments, understanding how variance is partitioned can guide decisions about how to allocate resources and determine sample sizes.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA provides a structured framework for analyzing and understanding the sources of variability in data. It's a key concept that underlies the hypothesis testing and interpretation process in ANOVA analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c14186-baf9-4c1e-8253-d9a3d4062ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6733ef82-bc1b-44bd-a736-609f14926d22",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3eacbe-443e-4eeb-9202-6153dc615c65",
   "metadata": {},
   "source": [
    "Ans---\n",
    "\n",
    "In a one-way ANOVA, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) to analyze the variance within the data. You can use Python and libraries like NumPy and SciPy to perform these calculations. Here's how you can calculate these sums of squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb807708-7fd0-4202-90a0-415915de26cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 664.9333333333333\n",
      "Explained Sum of Squares (SSE): 476.1333333333334\n",
      "Residual Sum of Squares (SSR): 188.8\n",
      "F-statistic: 15.131355932203391\n",
      "p-value: 0.0005240145076064184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([20, 25, 30, 28, 32])\n",
    "group2 = np.array([15, 18, 22, 20, 25])\n",
    "group3 = np.array([10, 12, 15, 11, 18])\n",
    "\n",
    "# Combine all data into a single array\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (group1_mean - overall_mean)**2 + \\\n",
    "      len(group2) * (group2_mean - overall_mean)**2 + \\\n",
    "      len(group3) * (group3_mean - overall_mean)**2\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = np.sum((group1 - group1_mean)**2) + \\\n",
    "      np.sum((group2 - group2_mean)**2) + \\\n",
    "      np.sum((group3 - group3_mean)**2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "\n",
    "# Calculate the degrees of freedom for SST, SSE, and SSR\n",
    "df_total = len(all_data) - 1\n",
    "df_groups = 3 - 1  # Number of groups minus 1\n",
    "df_residual = len(all_data) - 3  # Total - Number of groups\n",
    "\n",
    "# Calculate the Mean Square for groups (MSG) and residuals (MSR)\n",
    "msg = sse / df_groups\n",
    "msr = ssr / df_residual\n",
    "\n",
    "# Calculate the F-statistic\n",
    "f_statistic = msg / msr\n",
    "\n",
    "# Calculate the p-value using the F-distribution\n",
    "p_value = 1 - stats.f.cdf(f_statistic, df_groups, df_residual)\n",
    "\n",
    "# Print the F-statistic and p-value\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e662-7e8e-41e0-9b61-a839f04ee73a",
   "metadata": {},
   "source": [
    "In this example, replace the group1, group2, and group3 arrays with your own data for each group. The code calculates the SST, SSE, and SSR, and then it calculates the F-statistic and p-value for hypothesis testing. Make sure you have the NumPy and SciPy libraries installed to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac2eaf-ff35-42ac-bb83-616ad02e7954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b41add26-ba8a-4ccd-8fe1-60e823e4d296",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec637a77-fe55-46d2-a185-de4d601b57be",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "In a two-way ANOVA, you analyze the effects of two independent variables (factors) on a dependent variable. You can calculate the main effects of each factor and the interaction effect between the factors. Here's how you can calculate these effects using Python and the statsmodels library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f1dc0b-bf46-474a-b24a-b716bd20ef21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq   df             F        PR(>F)\n",
      "Factor1          4.860000e+02  1.0  9.720000e+02  6.373278e-07\n",
      "Factor2          3.750000e+01  1.0  7.500000e+01  3.392559e-04\n",
      "Factor1:Factor2  4.892170e-29  1.0  9.784340e-29  1.000000e+00\n",
      "Residual         2.500000e+00  5.0           NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Factor1': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'Factor2': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'Dependent': [10, 12, 15, 18, 20, 23, 28, 30, 33]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Dependent ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd7c43-370e-47e8-9d59-8be3d3851c32",
   "metadata": {},
   "source": [
    "In this example, replace the sample data in the data dictionary with your own data. The Factor1 and Factor2 columns represent the levels of the two independent variables, and the Dependent column represents the dependent variable.\n",
    "\n",
    "The ols function from the statsmodels library is used to fit the ANOVA model. The formula 'Dependent ~ Factor1 + Factor2 + Factor1:Factor2' specifies the model with main effects of Factor1 and Factor2, as well as their interaction (Factor1:Factor2).\n",
    "\n",
    "The sm.stats.anova_lm function calculates the ANOVA table, which includes the main effects of each factor and the interaction effect. The typ=2 argument specifies the type of sum of squares calculation to be used.\n",
    "\n",
    "The resulting ANOVA table will provide you with the F-statistics, degrees of freedom, p-values, and other information for each effect. This can help you assess the significance of the main effects and interaction effect in your two-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630926c9-d5ea-4ff0-a97c-73b161df54d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ab5718-9bf6-4b8f-9f89-951ef50db464",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d078f806-4c5d-4e69-86ef-07a9d5d6eaa5",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences in means among the groups. The associated p-value indicates the probability of observing such a large F-statistic under the assumption that there are no true differences between the group means (null hypothesis). A small p-value suggests that the observed differences are unlikely to have occurred by chance alone, leading to the rejection of the null hypothesis.\n",
    "\n",
    "In your scenario, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how you can interpret these results:\n",
    "\n",
    "1. **F-Statistic:** The F-statistic value of 5.23 indicates the ratio of variability between the group means to the variability within the groups. A larger F-statistic suggests a larger difference between group means relative to the variability within the groups.\n",
    "\n",
    "2. **P-Value:** The p-value of 0.02 is below the conventional significance level of 0.05. This indicates that the probability of observing such a large F-statistic under the assumption of no true differences between the group means is only 0.02. In other words, the p-value is small enough to suggest that the observed differences are statistically significant.\n",
    "\n",
    "3. **Conclusion:** Given the small p-value, you would reject the null hypothesis. This means that there are statistically significant differences between at least some of the group means. In practical terms, you have evidence to suggest that the groups are not all equal with respect to the variable being studied.\n",
    "\n",
    "4. **Practical Significance:** While statistical significance is important, it's also essential to consider the practical significance of the differences. Even though the differences are statistically significant, they might not be large enough to have meaningful implications in the real world. Interpretation of results should always take into account both statistical and practical significance.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there are statistically significant differences between the groups' means. This result suggests that the groups are not all equal with respect to the variable you examined in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81a55e-4c7e-4930-afb8-a7d4b531230e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eabe4f4e-bea1-481a-80b9-f433ae86823a",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2661506-242c-40d7-858e-f6537b2e12b1",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is important to ensure the accuracy and reliability of your analysis. Different methods for handling missing data can have varying effects on the results and conclusions of your study. Here are some common methods for handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "**1. Listwise Deletion:**\n",
    "Listwise deletion involves removing participants who have missing data on any of the measured variables. While it's a straightforward approach, it can lead to a loss of statistical power and potential bias if the missing data are not missing completely at random (MCAR). This method can result in a smaller sample size and potentially biased estimates of means and variances.\n",
    "\n",
    "**2. Pairwise Deletion:**\n",
    "Pairwise deletion involves using only the available data for each specific analysis, discarding incomplete cases on a pairwise basis. While this retains more data compared to listwise deletion, it can still lead to biased estimates and standard errors if the missing data are not MCAR. Additionally, the results may vary depending on which pairs of observations are used for analysis.\n",
    "\n",
    "**3. Imputation Methods:**\n",
    "Imputation involves estimating missing values based on observed values and certain assumptions. Common imputation methods include mean imputation (replacing missing values with the mean of the variable), regression imputation (predicting missing values based on other variables), and multiple imputation (creating multiple imputed datasets to account for uncertainty).\n",
    "\n",
    "   - **Potential Consequences:** While imputation can improve sample size and reduce bias compared to deletion methods, it introduces potential bias if the imputation model is misspecified. Additionally, imputed values may not reflect the true variability in the data, leading to underestimated standard errors and inflated significance levels.\n",
    "\n",
    "**4. Mixed Models (Longitudinal Models):**\n",
    "Mixed models (also known as hierarchical linear models or multilevel models) are advanced statistical methods that can handle missing data by utilizing all available data while accounting for the underlying structure of repeated measures data. These models can estimate both within-subject and between-subject effects and handle missing data patterns more flexibly.\n",
    "\n",
    "   - **Potential Consequences:** Mixed models provide a more accurate representation of the data's structure and can yield unbiased estimates even when data are missing not completely at random (MNAR). However, they might be more complex to implement and require assumptions about the missing data mechanism.\n",
    "\n",
    "**5. Sensitivity Analysis:**\n",
    "Performing sensitivity analyses involves assessing how different methods of handling missing data affect the results. By comparing the outcomes using different approaches, you can assess the robustness of your conclusions.\n",
    "\n",
    "In summary, the choice of method for handling missing data in a repeated measures ANOVA depends on the nature of the missing data and the assumptions you can reasonably make about the data mechanism. It's essential to carefully consider the potential consequences of each method and to report your chosen method and its rationale in your research findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d732881-50a7-4bf9-b714-c40b55ee3fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb7385e-1fe5-48c7-86b5-2a312b21be62",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1eb051-3a78-4835-b25d-b1a006edce81",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "\n",
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are used to determine which specific group means are significantly different from each other. Post-hoc tests help avoid the issue of inflating the Type I error rate when conducting multiple pairwise comparisons. There are several post-hoc tests available, and the choice depends on the design and assumptions of your study. Here are some common post-hoc tests and when to use them:\n",
    "\n",
    "**1. Tukey's Honestly Significant Difference (HSD):**\n",
    "Tukey's HSD is often used when you have a balanced design (equal sample sizes) and you want to compare all possible pairs of group means. It controls the familywise error rate, making it suitable for making multiple comparisons.\n",
    "\n",
    "**2. Bonferroni Correction:**\n",
    "The Bonferroni correction is a conservative approach that divides the desired alpha level by the number of comparisons being made. It's commonly used to control the overall Type I error rate when making multiple comparisons. It can be appropriate when you're concerned about making a large number of comparisons.\n",
    "\n",
    "**3. Scheffe's Method:**\n",
    "Scheffe's method is a more conservative post-hoc test that can be used with any design, including unbalanced designs. It provides a more general control of the Type I error rate, making it suitable for situations where you have complex designs or unequal sample sizes.\n",
    "\n",
    "**4. Dunnett's Test:**\n",
    "Dunnett's test is used when you have one control group and you want to compare each treatment group to the control group. This is particularly useful in situations where you have a predefined control group and are interested in assessing how other groups differ from it.\n",
    "\n",
    "**5. Games-Howell Test:**\n",
    "The Games-Howell test is appropriate when you have unequal variances and potentially unequal sample sizes among groups. It's a more robust alternative when the assumption of equal variances is violated.\n",
    "\n",
    "Example situation where a post-hoc test might be necessary:\n",
    "\n",
    "Suppose you're conducting a study to compare the effectiveness of three different teaching methods (A, B, and C) on student performance. After performing a one-way ANOVA, you find a significant difference in means (p < 0.05). Now, you want to know which specific teaching methods are different from each other.\n",
    "\n",
    "Here's how you might use a post-hoc test:\n",
    "\n",
    "1. Conduct the one-way ANOVA to determine overall differences.\n",
    "2. Since you have three teaching methods, you decide to perform a post-hoc test to compare the group means.\n",
    "3. Depending on the assumptions of your data (balanced vs. unbalanced, equal variances vs. unequal variances), you choose an appropriate post-hoc test like Tukey's HSD, Scheffe's method, or Games-Howell.\n",
    "4. Perform the post-hoc test to identify which specific pairs of teaching methods have significantly different means.\n",
    "5. Interpret the results to draw conclusions about the relative effectiveness of the teaching methods.\n",
    "\n",
    "Post-hoc tests provide valuable insights by helping you identify significant differences among group means while controlling for the increased chance of Type I error due to multiple comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66a6d9-b53d-4690-8897-e92eade6ecd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d23d30-58ac-4fcb-b586-452cb5cff365",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5fde15-0590-475a-96c5-445e4ff9909e",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "Here's an example of how you can conduct a one-way ANOVA using Python to analyze the mean weight loss of three diets (A, B, and C):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36894e80-7558-425a-9ba2-eb2fe85cd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1219.2978207428148\n",
      "p-value: 2.9827680935806507e-92\n",
      "There are significant differences in mean weight loss among the diet groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for weight loss in each diet group\n",
    "diet_A = np.array([2.5, 3.0, 2.2, 2.8, 2.6, 2.7, 2.9, 3.2, 2.8, 3.1,\n",
    "                   2.4, 2.7, 2.9, 2.5, 2.6, 2.8, 2.3, 2.5, 2.4, 2.6,\n",
    "                   2.7, 2.6, 2.8, 3.0, 2.9, 2.7, 2.4, 2.3, 2.5, 2.8,\n",
    "                   3.0, 2.7, 2.6, 2.4, 2.5, 2.9, 3.2, 2.3, 2.8, 2.5,\n",
    "                   2.6, 2.4, 2.2, 2.7, 2.8, 3.1, 2.9, 2.5, 2.6, 2.4])\n",
    "\n",
    "diet_B = np.array([1.8, 2.0, 1.9, 2.1, 1.7, 2.2, 2.5, 1.9, 2.3, 2.1,\n",
    "                   1.6, 2.0, 2.2, 2.3, 2.1, 1.8, 2.0, 2.3, 2.2, 2.1,\n",
    "                   2.0, 1.8, 1.9, 2.2, 2.1, 2.3, 2.0, 1.7, 2.2, 1.8,\n",
    "                   2.1, 1.9, 2.0, 2.3, 1.8, 2.1, 2.2, 2.0, 2.3, 2.1,\n",
    "                   2.0, 1.7, 1.9, 2.1, 1.8, 2.2, 2.0, 2.3, 2.1, 2.2])\n",
    "\n",
    "diet_C = np.array([0.5, 0.8, 0.7, 0.9, 0.6, 0.8, 0.9, 0.7, 0.6, 0.5,\n",
    "                   0.8, 0.9, 0.7, 0.6, 0.5, 0.9, 0.7, 0.8, 0.6, 0.7,\n",
    "                   0.8, 0.9, 0.5, 0.6, 0.7, 0.8, 0.9, 0.7, 0.5, 0.6,\n",
    "                   0.8, 0.9, 0.7, 0.6, 0.5, 0.8, 0.7, 0.6, 0.9, 0.8,\n",
    "                   0.5, 0.7, 0.9, 0.6, 0.8, 0.7, 0.5, 0.6, 0.9, 0.8])\n",
    "\n",
    "# Combine data from all diet groups\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Group labels for each observation\n",
    "group_labels = np.array(['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C))\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There are significant differences in mean weight loss among the diet groups.\")\n",
    "else:\n",
    "    print(\"There are no significant differences in mean weight loss among the diet groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79d09f-b457-4604-8c78-7936dc6d708c",
   "metadata": {},
   "source": [
    "In this example, the np.array objects diet_A, diet_B, and diet_C represent the weight loss data for each diet group. The stats.f_oneway function is used to perform the one-way ANOVA, and the F-statistic and p-value are printed. The p-value is then interpreted to determine whether there are significant differences in mean weight loss among the diet groups.\n",
    "\n",
    "Remember that you'll need the NumPy and SciPy libraries installed to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ccc2d-2706-485b-a7c3-11bb7a56e2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1535a756-29af-491b-9d87-f27f6ece3c96",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345961d3-9351-4173-b9ce-126b1ac0a78b",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "To conduct a two-way ANOVA in Python, you can use the statsmodels library. Here's how you can perform the analysis for the scenario you described:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a94814-18d0-47f4-9eb4-81b602c69ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                  2.922222   2.0  0.285864  0.752093\n",
      "C(Experience)                0.099920   1.0  0.019549  0.889138\n",
      "C(Software):C(Experience)    1.950725   2.0  0.190828  0.826632\n",
      "Residual                   429.341987  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 45),\n",
    "    'Time': np.random.normal(loc=15, scale=2, size=90)  # Simulated time data\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert Experience column to a categorical variable\n",
    "df['Experience'] = pd.Categorical(df['Experience'])\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478ba5b-2d39-42a3-8131-e53b46a5ff54",
   "metadata": {},
   "source": [
    "In this example, replace the simulated time data with your own time measurements. The Software and Experience columns represent the software program and employee experience level, respectively.\n",
    "\n",
    "The C() function is used to treat the variables as categorical factors. The interaction term C(Software):C(Experience) captures the interaction effect between software programs and experience levels.\n",
    "\n",
    "The anova_lm function calculates the ANOVA table, which includes the main effects of software programs, experience levels, and the interaction effect. The typ=2 argument specifies the type of sum of squares calculation.\n",
    "\n",
    "Interpretation of the results:\n",
    "- Check the p-values associated with each effect (Software, Experience, Interaction).\n",
    "- If any p-value is below the significance level (e.g., 0.05), you can conclude that there is a significant effect. The F-statistic measures the variance explained by that effect relative to the residual variance.\n",
    "- If the interaction effect is significant, it suggests that the combined effects of software programs and experience levels are not additive; they interact in influencing the task completion time.\n",
    "\n",
    "Remember that this example uses simulated data, so make sure to replace it with your actual data. Additionally, you need to have the numpy, pandas, and statsmodels libraries installed to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b1fc9-f46b-4c67-a2f1-536556bb00f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56bb8daa-c077-4c4f-8bec-f4070ef1616c",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448af43-626b-4bb7-aa81-38806fa043c6",
   "metadata": {},
   "source": [
    "Ans--\n",
    "\n",
    "Certainly! You can use Python and the scipy library to conduct a two-sample t-test to compare the test scores of the control and experimental groups. If the results are significant, you can follow up with a post-hoc test to identify which group(s) differ significantly. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dbb5a-2536-408d-b7ba-58173568b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "control_group = np.array([85, 78, 92, 70, 88, 80, 95, 72, 75, 85,\n",
    "                          88, 90, 78, 82, 80, 85, 76, 80, 84, 88,\n",
    "                          82, 86, 75, 79, 81, 77, 89, 74, 83, 79,\n",
    "                          85, 73, 81, 76, 88, 84, 82, 90, 86, 79,\n",
    "                          81, 84, 89, 83, 77, 80, 75, 88, 82, 86])\n",
    "\n",
    "experimental_group = np.array([92, 89, 98, 82, 94, 87, 96, 80, 85, 92,\n",
    "                               94, 96, 88, 90, 84, 91, 82, 86, 89, 93,\n",
    "                               90, 91, 81, 85, 88, 83, 95, 82, 88, 84,\n",
    "                               91, 79, 88, 82, 96, 90, 88, 97, 91, 85,\n",
    "                               89, 92, 95, 90, 84, 86, 82, 96, 88, 91])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# Perform post-hoc test (if significant)\n",
    "if p_value < alpha:\n",
    "    # Perform a post-hoc test (e.g., Tukey-Kramer) to determine which group(s) differ significantly\n",
    "    posthoc_results = stats.tukey_kramer(control_group, experimental_group)\n",
    "    print(\"Post-hoc test results:\")\n",
    "    print(posthoc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f21e4a-3124-491b-aa7d-1f88a62b74be",
   "metadata": {},
   "source": [
    "In this example, the control_group and experimental_group arrays represent the test scores of the control and experimental groups, respectively.\n",
    "\n",
    "The stats.ttest_ind function performs the two-sample t-test to compare the means of the two groups. The p-value is then compared to the significance level (alpha) to determine if there is a significant difference in test scores between the groups.\n",
    "\n",
    "If the results are significant, a post-hoc test (such as Tukey-Kramer) is performed to identify which group(s) differ significantly from each other. Make sure you have the numpy and scipy libraries installed to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd371ee4-7d23-4100-b0b1-31ef038a8fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba5b3176-a84e-405b-bcb9-b633b72fc3b6",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4ac94-3874-4f2e-b9f8-33ff01ab16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
